{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "deepnote_notebook_id": "823a8fe9-f880-4cc0-97b7-24a6f65c7736",
    "deepnote_execution_queue": [],
    "colab": {
      "name": "EV-train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d97W89AEQuHI",
        "outputId": "a8a363da-f77a-4d6b-e8c1-da8705723619",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he7MCkKoRMg1",
        "outputId": "0721a21a-6169-4e59-a312-10d5805bd75d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python -V"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phpm1w5ER1Uf",
        "outputId": "a1bfe9d1-3c5e-4bbd-df0a-57a7937a4946",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls 'drive/My Drive'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "â—¼NOT_ML\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00000-a85047ca-7ff1-498d-9a75-692513dc244f",
        "output_cleared": false,
        "source_hash": "e6f8aaaa",
        "execution_millis": 2,
        "execution_start": 1604212437611,
        "id": "pPaj_ZKnQNaA",
        "outputId": "dcfaf228-9301-4701-f19f-427b72656d93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(f'Tensorflow version: {tf.__version__}')\n",
        "tf.python.client.device_lib.list_local_devices()\n",
        "# print(\"# GPUs Available: \",\n",
        "#     len(tf.config.experimental.list_physical_devices())\n",
        "# )"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 5259982231170734814, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 13097794076312885569\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 18303885401548394544\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14640891840\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 6244286574083197730\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00000-f8e8edad-102d-4e5f-afdb-c34932a1267f",
        "output_cleared": false,
        "source_hash": "366d5474",
        "execution_millis": 12,
        "execution_start": 1604164877727,
        "id": "haV4T5EaQNaF",
        "outputId": "949af797-fdb7-477c-9499-b861b8e20338"
      },
      "source": [
        "# https://www.tensorflow.org/tutorials/images/classification\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "\n",
        "DATAPATH = \"/content/drive/My Drive/datasets/eeveelutions/sap/Labeled/SoloEevee\"\n",
        "VAL_SPLIT = 0.15\n",
        "IMG_HEIGHT = 160\n",
        "IMG_WIDTH = 160\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "RANDOM_SEED = 6110\n",
        "\n",
        "timestamp = int(time.time())\n",
        "tensorboard = TensorBoard(log_dir=f'tensorboard/eevee/{timestamp}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'D:/User/long/WORKSPACE_ALT/__coding__/ML/Keras/Dataset/sap1231-251020/Labeled/SoloEevee'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6118f16d7ac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_HEIGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_WIDTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bilinear\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     34\u001b[0m val_ds = image_dataset_from_directory(\n",
            "\u001b[0;32m/opt/venv/lib/python3.7/site-packages/tensorflow/python/keras/preprocessing/image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links)\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m       follow_links=follow_links)\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlabel_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/venv/lib/python3.7/site-packages/tensorflow/python/keras/preprocessing/dataset_utils.py\u001b[0m in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[1;32m     63\u001b[0m   \"\"\"\n\u001b[1;32m     64\u001b[0m   \u001b[0minferred_class_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m       \u001b[0minferred_class_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/User/long/WORKSPACE_ALT/__coding__/ML/Keras/Dataset/sap1231-251020/Labeled/SoloEevee'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00001-ebbb90d1-abd1-449f-9f13-d033ccd8cb39",
        "id": "KjKjGA5bQNaI"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "\n",
        "train_ds = image_dataset_from_directory(\n",
        "    DATAPATH,\n",
        "    # label_mode='categorical',\n",
        "    validation_split=VAL_SPLIT,\n",
        "    subset=\"training\",\n",
        "    seed=RANDOM_SEED,\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    interpolation=\"bilinear\",\n",
        ")\n",
        "val_ds = image_dataset_from_directory(\n",
        "    DATAPATH,\n",
        "    validation_split=VAL_SPLIT,\n",
        "    subset=\"validation\",\n",
        "    seed=RANDOM_SEED,\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        ")\n",
        "print(train_ds.class_names)\n",
        "\n",
        "\n",
        "# AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "# train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "# val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00002-d1410851-6887-4122-b812-b421c237a7f9",
        "id": "iFMLJKShQNaK"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.experimental.preprocessing.RandomFlip(\n",
        "        \"horizontal\",\n",
        "        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
        "    ),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomContrast(0.1),\n",
        "    layers.experimental.preprocessing.RandomTranslation(0.1, 0.1),\n",
        "])\n",
        "\n",
        "# https://keras.io/api/applications/ \"Fine-tune InceptionV3 on a new set of classes\"\n",
        "# https://keras.io/api/applications/mobilenet/\n",
        "model = keras.Sequential([\n",
        "    # data_augmentation,\n",
        "    layers.experimental.preprocessing.Rescaling(\n",
        "        scale=1./127.5, offset=-1, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    keras.applications.mobilenet_v2.MobileNetV2(\n",
        "        alpha=0.35, # width multiplier\n",
        "        # depth_multiplier=1,\n",
        "        include_top=False,\n",
        "        pooling=\"avg\",\n",
        "        classes=9,\n",
        "    ),\n",
        "    # layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.1),\n",
        "    layers.Dense(9,\n",
        "        # activation='softmax'\n",
        "    )\n",
        "])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00004-d7658df9-10ea-4a21-9448-7277b4afe5d8",
        "id": "PcR1zz-hQNaM"
      },
      "source": [
        "# https://keras.io/api/models/model_training_apis/\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.0),\n",
        "    # loss='categorical_crossentropy',\n",
        "    # optimizer=keras.optimizers.Adam(lr=0.002),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00001-5b49c486-d2ae-4249-a79b-c178e532bec3",
        "output_cleared": false,
        "source_hash": "6b8cdf78",
        "id": "80rf8AZqQNaO"
      },
      "source": [
        "model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1,\n",
        "    callbacks=[tensorboard],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00003-9759df19-20a0-4696-ab9a-97748d65e1b4",
        "id": "6Y2e1ouAQNaQ"
      },
      "source": [
        "import tensorflowjs as tfjs\n",
        "\n",
        "model.save(f\"EV-classify-{timestamp}.keras\")\n",
        "tfjs.converters.save_keras_model(model, \"D:/User/long/WORKSPACE_ALT/__coding__/ML/Keras\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}