{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EV_train.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "G-X0wBQ-71yD",
        "kQf7R0Dt8HoR",
        "TkJfeOOY8OYC",
        "JibRwx1V8bRH"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/catPotat/EV-classifier/blob/main/EV_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT1gfRvBDUBj"
      },
      "source": [
        "# About\n",
        "\n",
        "#### Keras utilization of MobileNetV2 to recognize Eeveelution types\n",
        "(WIP 80% val_accuracy, feel free to add any comment Ctrl+Alt+M)\n",
        "\n",
        " \n",
        "By: *Reeeon*\n",
        " \n",
        "Thanks to:\n",
        "* *Sap1231 for eight thousands pics*\n",
        "* *Eevee Hub#eeveelution-pictures for three thousands pics*\n",
        "\n",
        "All them pics labeled:\n",
        "1. https://drive.google.com/file/d/1_ZcLupdcWQbVsZH_ET5c1Rp3gAMIZ4TH\n",
        "2. soon\n",
        "\n",
        "Trained weights: https://drive.google.com/drive/folders/1ZG8oJHYzCCzg6e848MopcKjqQBHvfqvQ\n",
        "\n",
        " \n",
        "<img src=\"https://drive.google.com/uc?id=1KTToAwFHae2gCGcjZb7_CDn12xq003B2\" alt=\"cute umbreon picture\" height>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaPjfASQ_34t"
      },
      "source": [
        "# üèÅ Initialize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYBqLX06rQL-"
      },
      "source": [
        "!python -V\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzPQYTebrfSr"
      },
      "source": [
        "!mkdir -p datasets/{fragments,Labeled}/\n",
        "!unzip \"drive/My Drive/datasets/Eeveelutions/sap1231-251020.zip\" -d datasets/fragments/\n",
        "!mv datasets/fragments/sap1231-251020/Labeled/* datasets/Labeled/\n",
        "# unzip my new ds \n",
        "# !mv --backup=t datasets/fragments/evhub#evlution-pics/Labeled/* datasets/Labeled/\n",
        "\n",
        "output.clear()\n",
        "print(\"Datasets loaded!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBo87natrhC-"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(f'Tensorflow version: {tf.__version__}')\n",
        "# tf.python.client.device_lib.list_local_devices()\n",
        "print(\"# GPUs Available: \",\n",
        "    len(tf.config.experimental.list_physical_devices(\"GPU\"))\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3xT1TXqBRCj"
      },
      "source": [
        "# üìà Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPRMmLN-Ba-p"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1LLjX-j9XSN"
      },
      "source": [
        "üëá *Test and tune then re-run from here (Ctrl+F10)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKEd250v8jdH"
      },
      "source": [
        "# üî¢ Some hyperparams or somethin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3GZZnWI6BRZ"
      },
      "source": [
        "DATA_PATH = \"datasets/Labeled/SoloEevee/\"\n",
        "MODEL_PATH = \"drive/My Drive/Colab Notebooks/EV-classifier/EV_trained/\"\n",
        "VAL_SPLIT = 0.15\n",
        "IMG_HEIGHT = 299\n",
        "IMG_WIDTH = 299\n",
        "BATCH_SIZE = 32 # 32 good for testing\n",
        "EPOCHS = 18\n",
        "LEARNING_RATE = 0.00001\n",
        "RANDOM_SEED = 6110\n",
        "\n",
        "!ls $DATA_PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myRzzN5zrlQ7"
      },
      "source": [
        "# https://www.tensorflow.org/tutorials/images/classification\n",
        "\n",
        "import time\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "\n",
        "timestamp = int(time.time())\n",
        "tensorboard = TensorBoard(log_dir=f'logs/eevee/{timestamp}')\n",
        "print(f'Timestamp: {timestamp}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-X0wBQ-71yD"
      },
      "source": [
        "# üóÇÔ∏è Prepare thee dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zneM5i6Jrndv"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "\n",
        "train_ds = image_dataset_from_directory(\n",
        "    DATA_PATH,\n",
        "    # label_mode='categorical',\n",
        "    validation_split=VAL_SPLIT,\n",
        "    subset=\"training\",\n",
        "    seed=RANDOM_SEED,\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=True\n",
        ")\n",
        "val_ds = image_dataset_from_directory(\n",
        "    DATA_PATH,\n",
        "    validation_split=VAL_SPLIT,\n",
        "    subset=\"validation\",\n",
        "    seed=RANDOM_SEED,\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    follow_links=True\n",
        ")\n",
        "print(train_ds.class_names)\n",
        "\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQf7R0Dt8HoR"
      },
      "source": [
        "# üß† Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiq5TVJTrpN6"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", seed=RANDOM_SEED,\n",
        "        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    layers.experimental.preprocessing.RandomContrast(0.1, seed=RANDOM_SEED),\n",
        "    # layers.experimental.preprocessing.RandomRotation(0.1), # terrible results\n",
        "    # layers.experimental.preprocessing.RandomTranslation(0.1, 0.1),\n",
        "    layers.experimental.preprocessing.RandomWidth(\n",
        "        0.1, seed=RANDOM_SEED, interpolation='bilinear'),\n",
        "])\n",
        "\n",
        "# https://keras.io/api/applications/ \"Fine-tune InceptionV3 on a new set of classes\"\n",
        "# https://keras.io/api/applications/mobilenet/\n",
        "model = keras.Sequential([\n",
        "    # data_augmentation,\n",
        "    layers.experimental.preprocessing.Rescaling(\n",
        "        scale=1./127.5, offset=-1, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    keras.applications.mobilenet_v2.MobileNetV2(\n",
        "        alpha=0.5,\n",
        "        weights=\"imagenet\",\n",
        "        include_top=False,\n",
        "        pooling=\"avg\",\n",
        "    ),\n",
        "    # layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.1),\n",
        "    layers.Dense(9, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkJfeOOY8OYC"
      },
      "source": [
        "# üßÆ Pick your optimizer, loss fn, etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZRRvi-2rrcy"
      },
      "source": [
        "# https://keras.io/api/models/model_training_apis/\n",
        "\n",
        "model.compile(\n",
        "    # optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.0),\n",
        "    # loss='categorical_crossentropy',\n",
        "    optimizer=keras.optimizers.Adam(lr=LEARNING_RATE),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(f'Default GPU Device: {tf.test.gpu_device_name()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JibRwx1V8bRH"
      },
      "source": [
        "# **üöß Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loG201-DruE5"
      },
      "source": [
        "model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1,\n",
        "    callbacks=[tensorboard],\n",
        ")\n",
        "\n",
        "model.save(f'EV-classify-{timestamp}.keras') # backup\n",
        "print(\"Model exported!\")\n",
        "!mkdir -p \"$MODEL_PATH/$timestamp\"\n",
        "model.save(f'{MODEL_PATH}/{timestamp}/EV-classify-{timestamp}.keras')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yzYyAoKrufY"
      },
      "source": [
        "!pip install tensorflowjs\n",
        "output.clear()\n",
        "\n",
        "import tensorflowjs as tfjs\n",
        "\n",
        "tfjs.converters.save_keras_model(model, f'{MODEL_PATH}/{timestamp}/')\n",
        "print(\"JSON model saved!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}